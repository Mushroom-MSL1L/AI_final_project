{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKeV9jD8ugte"
      },
      "source": [
        "# upload all folder and file(from github) as one folder to your googleDrive\n",
        "**Attention: no need to upload llama.cpp folder in Model folder, since the size is too large.\n",
        "We will directly download from huggingface later.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJXD3QFwStNM",
        "outputId": "387091e4-ae0c-483d-cc0d-b24ff6b195dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/AI_final_project_SteamHotCommentFetcher\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/MyDrive/AI_final_project_SteamHotCommentFetcher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZFmOTt4ugtg"
      },
      "source": [
        "# install all modules required\n",
        "\n",
        "*   install pytorch as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FebGQ-28O4q",
        "outputId": "c6b16fb3-d00e-41e2-aefb-fbddc48470d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPx2jvM00Jea",
        "outputId": "b927c90e-af12-47e4-b53b-804677ececaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain==0.1.20 (from -r requirements.txt (line 1))\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-community==0.0.38 (from -r requirements.txt (line 2))\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core==0.1.52 (from -r requirements.txt (line 3))\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chainlit==1.1.202 (from -r requirements.txt (line 4))\n",
            "  Downloading chainlit-1.1.202-py3-none-any.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chromadb==0.5.0 (from -r requirements.txt (line 5))\n",
            "  Downloading chromadb-0.5.0-py3-none-any.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama_cpp_python==0.2.73 (from -r requirements.txt (line 6))\n",
            "  Downloading llama_cpp_python-0.2.73.tar.gz (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gguf==0.6.0 (from -r requirements.txt (line 7))\n",
            "  Downloading gguf-0.6.0-py3-none-any.whl (23 kB)\n",
            "Collecting sentence-transformers==2.7.0 (from -r requirements.txt (line 8))\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langid==1.1.6 (from -r requirements.txt (line 9))\n",
            "  Downloading langid-1.1.6.tar.gz (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hf_transfer==0.1.6 (from -r requirements.txt (line 11))\n",
            "  Downloading hf_transfer-0.1.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv==1.0.1 (from -r requirements.txt (line 12))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting langchain-fireworks==0.1.3 (from -r requirements.txt (line 13))\n",
            "  Downloading langchain_fireworks-0.1.3-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.20->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.20->-r requirements.txt (line 1)) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.20->-r requirements.txt (line 1)) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.20->-r requirements.txt (line 1)) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.20->-r requirements.txt (line 1))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain==0.1.20->-r requirements.txt (line 1))\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.1.20->-r requirements.txt (line 1))\n",
            "  Downloading langsmith-0.1.76-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.20->-r requirements.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.20->-r requirements.txt (line 1)) (2.7.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.20->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.20->-r requirements.txt (line 1)) (8.3.0)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core==0.1.52->-r requirements.txt (line 3))\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core==0.1.52->-r requirements.txt (line 3))\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0.0,>=23.1.0 (from chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting asyncer<0.0.3,>=0.0.2 (from chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading asyncer-0.0.2-py3-none-any.whl (8.3 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from chainlit==1.1.202->-r requirements.txt (line 4)) (8.1.7)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.20->-r requirements.txt (line 1))\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting fastapi<0.111.0,>=0.110.1 (from chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading fastapi-0.110.3-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-socketio<0.0.11,>=0.0.10 (from chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading fastapi_socketio-0.0.10-py3-none-any.whl (7.4 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Collecting httpx>=0.23.0 (from chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lazify<0.5.0,>=0.4.0 (from chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading Lazify-0.4.0-py2.py3-none-any.whl (3.1 kB)\n",
            "Collecting literalai==0.0.601 (from chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading literalai-0.0.601.tar.gz (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from chainlit==1.1.202->-r requirements.txt (line 4)) (1.6.0)\n",
            "Collecting pyjwt<3.0.0,>=2.8.0 (from chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Collecting python-multipart<0.0.10,>=0.0.9 (from chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting syncer<3.0.0,>=2.0.3 (from chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading syncer-2.0.3.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from chainlit==1.1.202->-r requirements.txt (line 4)) (2.0.1)\n",
            "Collecting uptrace<2.0.0,>=1.22.0 (from chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading uptrace-1.24.0-py3-none-any.whl (8.6 kB)\n",
            "Collecting uvicorn<0.26.0,>=0.25.0 (from chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading uvicorn-0.25.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles<0.21.0,>=0.20.0 (from chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading watchfiles-0.20.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.0->-r requirements.txt (line 5)) (1.2.1)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.0->-r requirements.txt (line 5)) (4.12.1)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading onnxruntime-1.18.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.0->-r requirements.txt (line 5)) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.0->-r requirements.txt (line 5)) (4.66.4)\n",
            "Collecting overrides>=7.3.1 (from chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.0->-r requirements.txt (line 5)) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.0->-r requirements.txt (line 5)) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.0->-r requirements.txt (line 5)) (0.9.4)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mmh3>=4.0.1 (from chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading orjson-3.10.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache>=5.6.1 (from llama_cpp_python==0.2.73->-r requirements.txt (line 6))\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama_cpp_python==0.2.73->-r requirements.txt (line 6)) (3.1.4)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0->-r requirements.txt (line 8)) (4.41.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0->-r requirements.txt (line 8)) (2.3.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0->-r requirements.txt (line 8)) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0->-r requirements.txt (line 8)) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0->-r requirements.txt (line 8)) (0.23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.7.0->-r requirements.txt (line 8)) (9.4.0)\n",
            "Collecting fireworks-ai>=0.13.0 (from langchain-fireworks==0.1.3->-r requirements.txt (line 13))\n",
            "  Downloading fireworks_ai-0.14.0-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.8/81.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai<2.0.0,>=1.10.0 (from langchain-fireworks==0.1.3->-r requirements.txt (line 13))\n",
            "  Downloading openai-1.33.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chevron>=0.14.0 (from literalai==0.0.601->chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading chevron-0.14.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20->-r requirements.txt (line 1)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20->-r requirements.txt (line 1)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.20->-r requirements.txt (line 1)) (1.9.4)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from asyncer<0.0.3,>=0.0.2->chainlit==1.1.202->-r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb==0.5.0->-r requirements.txt (line 5)) (1.1.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.20->-r requirements.txt (line 1))\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.20->-r requirements.txt (line 1))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting python-socketio>=4.6.0 (from fastapi-socketio<0.0.11,>=0.0.10->chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading python_socketio-5.11.2-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx-sse (from fireworks-ai>=0.13.0->langchain-fireworks==0.1.3->-r requirements.txt (line 13))\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->chainlit==1.1.202->-r requirements.txt (line 4)) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.23.0->chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->chainlit==1.1.202->-r requirements.txt (line 4)) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->chainlit==1.1.202->-r requirements.txt (line 4)) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.23.0->chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.7.0->-r requirements.txt (line 8)) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers==2.7.0->-r requirements.txt (line 8)) (2023.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama_cpp_python==0.2.73->-r requirements.txt (line 6)) (2.1.5)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core==0.1.52->-r requirements.txt (line 3))\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r requirements.txt (line 5)) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r requirements.txt (line 5)) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r requirements.txt (line 5)) (2.0.7)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.0->-r requirements.txt (line 5)) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.0->-r requirements.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.0->-r requirements.txt (line 5)) (1.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-fireworks==0.1.3->-r requirements.txt (line 13)) (1.7.0)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.5.0->-r requirements.txt (line 5)) (7.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.0->-r requirements.txt (line 5)) (1.63.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r requirements.txt (line 5)) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r requirements.txt (line 5)) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.20->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.20->-r requirements.txt (line 1)) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.20->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.20->-r requirements.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0->-r requirements.txt (line 8)) (3.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers==2.7.0->-r requirements.txt (line 8))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers==2.7.0->-r requirements.txt (line 8))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers==2.7.0->-r requirements.txt (line 8))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers==2.7.0->-r requirements.txt (line 8))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers==2.7.0->-r requirements.txt (line 8))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers==2.7.0->-r requirements.txt (line 8))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers==2.7.0->-r requirements.txt (line 8))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers==2.7.0->-r requirements.txt (line 8))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers==2.7.0->-r requirements.txt (line 8))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence-transformers==2.7.0->-r requirements.txt (line 8))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers==2.7.0->-r requirements.txt (line 8))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==2.7.0->-r requirements.txt (line 8)) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers==2.7.0->-r requirements.txt (line 8))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers==2.7.0->-r requirements.txt (line 8)) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers==2.7.0->-r requirements.txt (line 8)) (0.4.3)\n",
            "Collecting opentelemetry-exporter-otlp~=1.24 (from uptrace<2.0.0,>=1.22.0->chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading opentelemetry_exporter_otlp-1.25.0-py3-none-any.whl (7.0 kB)\n",
            "INFO: pip is looking at multiple versions of uvicorn[standard] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting uvicorn[standard]>=0.18.3 (from chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading uvicorn-0.30.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading uvicorn-0.28.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading uvicorn-0.28.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading uvicorn-0.27.0.post1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.7/60.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading uvicorn-0.27.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of uvicorn[standard] to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading uvicorn-0.26.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn<0.26.0,>=0.25.0->chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn<0.26.0,>=0.25.0->chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn<0.26.0,>=0.25.0->chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.7.0->-r requirements.txt (line 8)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.7.0->-r requirements.txt (line 8)) (3.5.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.4.0->asyncer<0.0.3,>=0.0.2->chainlit==1.1.202->-r requirements.txt (line 4)) (1.2.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.0->-r requirements.txt (line 5)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.0->-r requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.0->-r requirements.txt (line 5)) (4.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.5.0->-r requirements.txt (line 5)) (3.19.1)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http==1.25.0 (from opentelemetry-exporter-otlp~=1.24->uptrace<2.0.0,>=1.22.0->chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.25.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit==1.1.202->-r requirements.txt (line 4)) (0.23.1)\n",
            "Collecting python-engineio>=4.8.0 (from python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading python_engineio-4.9.1-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.20->-r requirements.txt (line 1))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.5.0->-r requirements.txt (line 5))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.5.0->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.0->-r requirements.txt (line 5)) (0.6.0)\n",
            "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.8.0->python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading simple_websocket-1.0.0-py3-none-any.whl (13 kB)\n",
            "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit==1.1.202->-r requirements.txt (line 4))\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: llama_cpp_python, langid, literalai, pypika, syncer\n",
            "  Building wheel for llama_cpp_python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama_cpp_python: filename=llama_cpp_python-0.2.73-cp310-cp310-linux_x86_64.whl size=3685385 sha256=260ea13aab12c47cc0ce72b68283106ccafe809ba4673d2020288ce7b8b71541\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/96/43/7e194c954ac912d68301956136f2b931efadf8f56c71fd5400\n",
            "  Building wheel for langid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941172 sha256=449345a91ec1d4ab66949e063d0f89f4fcd798b4dcc20d40bdcecdcc4b5ea258\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/c8/c6/eed80894918490a175677414d40bd7c851413bbe03d4856c3c\n",
            "  Building wheel for literalai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for literalai: filename=literalai-0.0.601-py3-none-any.whl size=60063 sha256=619529f5f1f37f33edd295baa3b36e9ddc1e3664766b00c0c5eb7af8d7722a5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/8f/ce/9313deae3102143ae1e668912db7a4910973a395f23a914857\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=a8ce20a3143cb1e5b2c1e39416ce4446adfbc62063fbcbb3358aa955973ff53c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "  Building wheel for syncer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for syncer: filename=syncer-2.0.3-py2.py3-none-any.whl size=3436 sha256=578e8a7f7244915cd30656623075d5c0b33010eea5d496b29b50c55b3a3302f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/09/e4/36/bcaad665bcc2b672888ff2df1a5a1dc638378d8765055313cd\n",
            "Successfully built llama_cpp_python langid literalai pypika syncer\n",
            "Installing collected packages: syncer, pypika, monotonic, mmh3, lazify, filetype, chevron, websockets, uvloop, python-multipart, python-dotenv, pyjwt, packaging, overrides, orjson, opentelemetry-util-http, opentelemetry-proto, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, langid, jsonpointer, humanfriendly, httpx-sse, httptools, hf_transfer, h11, gguf, diskcache, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, aiofiles, wsproto, watchfiles, uvicorn, typing-inspect, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, marshmallow, llama_cpp_python, jsonpatch, httpcore, coloredlogs, asyncer, simple-websocket, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, nvidia-cusolver-cu12, langsmith, kubernetes, httpx, fastapi, dataclasses-json, python-engineio, opentelemetry-sdk, opentelemetry-instrumentation-asgi, openai, literalai, langchain-core, fireworks-ai, sentence-transformers, python-socketio, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain-fireworks, langchain-community, opentelemetry-exporter-otlp, langchain, fastapi-socketio, chromadb, uptrace, chainlit\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.3.0\n",
            "    Uninstalling PyJWT-2.3.0:\n",
            "      Successfully uninstalled PyJWT-2.3.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed aiofiles-23.2.1 asgiref-3.8.1 asyncer-0.0.2 backoff-2.2.1 bcrypt-4.1.3 chainlit-1.1.202 chevron-0.14.0 chroma-hnswlib-0.7.3 chromadb-0.5.0 coloredlogs-15.0.1 dataclasses-json-0.5.14 deprecated-1.2.14 diskcache-5.6.3 fastapi-0.110.3 fastapi-socketio-0.0.10 filetype-1.2.0 fireworks-ai-0.14.0 gguf-0.6.0 h11-0.14.0 hf_transfer-0.1.6 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 httpx-sse-0.4.0 humanfriendly-10.0 jsonpatch-1.33 jsonpointer-3.0.0 kubernetes-30.1.0 langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.52 langchain-fireworks-0.1.3 langchain-text-splitters-0.0.2 langid-1.1.6 langsmith-0.1.76 lazify-0.4.0 literalai-0.0.601 llama_cpp_python-0.2.73 marshmallow-3.21.3 mmh3-4.1.0 monotonic-1.6 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 onnxruntime-1.18.0 openai-1.33.0 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-exporter-otlp-proto-http-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opentelemetry-util-http-0.46b0 orjson-3.10.4 overrides-7.7.0 packaging-23.2 posthog-3.5.0 pyjwt-2.8.0 pypika-0.48.9 python-dotenv-1.0.1 python-engineio-4.9.1 python-multipart-0.0.9 python-socketio-5.11.2 sentence-transformers-2.7.0 simple-websocket-1.0.0 starlette-0.37.2 syncer-2.0.3 typing-inspect-0.9.0 uptrace-1.24.0 uvicorn-0.25.0 uvloop-0.19.0 watchfiles-0.20.0 websockets-12.0 wsproto-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPV50tQZugtg"
      },
      "source": [
        "# Download llm model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJveBw6PO6FE",
        "outputId": "97df26c6-0ed1-49a8-99ae-78b41a8a8a26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/AI_final_project_SteamHotCommentFetcher/Model/llama.cpp\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/commands/download.py:132: FutureWarning: Ignoring --local-dir-use-symlinks. Downloading to a local directory does not use symlinks anymore.\n",
            "  warnings.warn(\n",
            "Downloading 'llama-2-7b-chat.Q4_K_M.gguf' to '.huggingface/download/llama-2-7b-chat.Q4_K_M.gguf.08a5566d61d7cb6b420c3e4387a39e0078e1f2fe5f055f3a03887385304d4bfa.incomplete'\n",
            "llama-2-7b-chat.Q4_K_M.gguf: 100% 4.08G/4.08G [00:33<00:00, 120MB/s]\n",
            "Download complete. Moving file to llama-2-7b-chat.Q4_K_M.gguf\n",
            "llama-2-7b-chat.Q4_K_M.gguf\n",
            "/content/gdrive/MyDrive/AI_final_project_SteamHotCommentFetcher\n"
          ]
        }
      ],
      "source": [
        "%cd Model/llama.cpp\n",
        "!mkdir llama.cpp\n",
        "!HUGGINGFACE_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli download TheBloke/Llama-2-7B-chat-GGUF llama-2-7b-chat.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False\n",
        "%cd ../../"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c51xuLXIugtg"
      },
      "source": [
        "#  llama-cpp-python GPU ver. install\n",
        "take almost 10 minitues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wI-hWuc5hkX",
        "outputId": "556615b3-5964-41a7-f6c7-fbac908baad5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.78.tar.gz (50.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting typing-extensions>=4.5.0 (from llama-cpp-python)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Collecting numpy>=1.20.0 (from llama-cpp-python)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2>=2.11.3 (from llama-cpp-python)\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.78-cp310-cp310-linux_x86_64.whl size=169183822 sha256=3a1dd398543dbb5400c65cdca1e76540e197fe47922020fe312054f8ac46da3f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oq7luhom/wheels/fd/c5/bd/3b1c20081bd71ce9d28b562573c97915c790bf1ef231879a61\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: typing-extensions, numpy, MarkupSafe, diskcache, jinja2, llama-cpp-python\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.1\n",
            "    Uninstalling typing_extensions-4.12.1:\n",
            "      Successfully uninstalled typing_extensions-4.12.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.5\n",
            "    Uninstalling MarkupSafe-2.1.5:\n",
            "      Successfully uninstalled MarkupSafe-2.1.5\n",
            "  Attempting uninstall: diskcache\n",
            "    Found existing installation: diskcache 5.6.3\n",
            "    Uninstalling diskcache-5.6.3:\n",
            "      Successfully uninstalled diskcache-5.6.3\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.4\n",
            "    Uninstalling Jinja2-3.1.4:\n",
            "      Successfully uninstalled Jinja2-3.1.4\n",
            "  Attempting uninstall: llama-cpp-python\n",
            "    Found existing installation: llama_cpp_python 0.2.73\n",
            "    Uninstalling llama_cpp_python-0.2.73:\n",
            "      Successfully uninstalled llama_cpp_python-0.2.73\n",
            "Successfully installed MarkupSafe-2.1.5 diskcache-5.6.3 jinja2-3.1.4 llama-cpp-python-0.2.78 numpy-1.26.4 typing-extensions-4.12.2\n"
          ]
        }
      ],
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install --upgrade --force-reinstall llama-cpp-python --no-cache-dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFM34ox0u8rU"
      },
      "source": [
        "# **Run**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeMtHU1mpdBu",
        "outputId": "624a354b-7f11-44e2-c752-52e26637d77b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m418.4/418.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install chainlit pyngrok langchain optimum auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/ -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ly_pRcPLCKY"
      },
      "outputs": [],
      "source": [
        "!ngrok http --domain=jointly-amazing-beagle.ngrok-free.app 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xo3bUTAHD5wp"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **When everytime you run chainlit, please run follow two commands beforehand to get URL!!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!ngrok config add-authtoken YOUR_AUTH_TOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ-apHBex3UF",
        "outputId": "feea5dda-990e-4d9f-8303-8ab53aa2584b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://20da-35-188-142-157.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "print(ngrok.connect(8000).public_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOIj-HpWEfyS"
      },
      "source": [
        "### Please jump to above url if you see following sentences in the console\n",
        "\n",
        "**Your app is available at http://localhost:8000**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BIt5k9TCnZy",
        "outputId": "dbd570ba-7b17-4a78-a8fb-3149836737f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-11 14:58:59 - Loaded .env file\n",
            "2024-06-11 14:59:08 - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:161: UserWarning: WARNING! temparature is not default parameter.\n",
            "                temparature was transferred to model_kwargs.\n",
            "                Please confirm that temparature is what you intended.\n",
            "  warnings.warn(\n",
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from Model/llama.cpp/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens cache size = 259\n",
            "llm_load_vocab: token to piece cache size = 0.1684 MB\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:   no\n",
            "ggml_cuda_init: CUDA_USE_TENSOR_CORES: yes\n",
            "ggml_cuda_init: found 1 CUDA devices:\n",
            "  Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
            "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 33/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =    70.31 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  3820.94 MiB\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 4096\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =  2048.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 2048.00 MiB, K (f16): 1024.00 MiB, V (f16): 1024.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   296.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =    16.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 2\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: llama-2\n",
            "2024-06-11 14:59:24 - Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
            "2024-06-11 14:59:25 - Collection steam_reviews is not created.\n",
            "2024-06-11 14:59:25 - Collection cursor is not created.\n",
            "2024-06-11 14:59:25 - Your app is available at http://localhost:8000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-06-11T14:59:35+0000 lvl=warn msg=\"failed to open private leg\" id=e623f264f0ad privaddr=localhost:8000 err=\"dial tcp 127.0.0.1:8000: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-06-11T14:59:35+0000 lvl=warn msg=\"failed to open private leg\" id=851d467d904a privaddr=localhost:8000 err=\"dial tcp 127.0.0.1:8000: connect: connection refused\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-06-11 14:59:42 - Translation file for ja not found. Using default translation en-US.\n",
            "2024-06-11 14:59:43 - Translated markdown file for ja not found. Defaulting to chainlit.md.\n",
            "2024-06-11 14:59:50 - 1 change detected\n",
            "2024-06-11 14:59:50 - 1 change detected\n",
            "2024-06-11 14:59:50 - 2 changes detected\n",
            "2024-06-11 14:59:50 - 2 changes detected\n",
            "2024-06-11 14:59:50 - 2 changes detected\n",
            "2024-06-11 14:59:50 - 2 changes detected\n",
            "2024-06-11 14:59:50 - 2 changes detected\n",
            "2024-06-11 14:59:51 - 1 change detected\n",
            "2024-06-11 14:59:51 - 1 change detected\n",
            "2024-06-11 14:59:51 - 2 changes detected\n",
            "2024-06-11 14:59:51 - 2 changes detected\n",
            "2024-06-11 14:59:51 - 2 changes detected\n",
            "2024-06-11 14:59:51 - 2 changes detected\n",
            "2024-06-11 14:59:51 - 2 changes detected\n",
            "2024-06-11 14:59:51 - 2 changes detected\n",
            "2024-06-11 14:59:51 - 2 changes detected\n",
            "2024-06-11 14:59:52 - 2 changes detected\n",
            "2024-06-11 14:59:52 - 2 changes detected\n",
            "2024-06-11 14:59:52 - 2 changes detected\n",
            "2024-06-11 14:59:52 - 2 changes detected\n",
            "2024-06-11 14:59:52 - 2 changes detected\n",
            "2024-06-11 14:59:52 - 2 changes detected\n",
            "2024-06-11 14:59:52 - 2 changes detected\n",
            "2024-06-11 14:59:52 - 2 changes detected\n",
            "2024-06-11 14:59:52 - Translation file for ja not found. Using default translation en-US.\n",
            "2024-06-11 14:59:52 - 2 changes detected\n",
            "2024-06-11 14:59:53 - 3 changes detected\n",
            "2024-06-11 14:59:56 - 7 changes detected\n",
            "game_id: 346110\n",
            "2024-06-11 14:59:56 - initializing identifier\n",
            "2024-06-11 15:00:00 - Translation file for ja not found. Using default translation en-US.\n",
            "2024-06-11 15:00:10 - 1 change detected\n",
            "2024-06-11 15:00:11 - 1 change detected\n",
            "Batches:   0% 0/1 [00:00<?, ?it/s]2024-06-11 15:00:11 - 1 change detected\n",
            "2024-06-11 15:00:11 - 1 change detected\n",
            "2024-06-11 15:00:11 - 1 change detected\n",
            "Batches: 100% 1/1 [00:00<00:00,  2.78it/s]\n",
            "cursor:  AoJ4hKPKvo4DefOf6AQ=\n",
            "Batches:   0% 0/32 [00:00<?, ?it/s]2024-06-11 15:00:12 - 3 changes detected\n",
            "Batches:   6% 2/32 [00:07<01:44,  3.47s/it]2024-06-11 15:00:19 - Translation file for ja not found. Using default translation en-US.\n",
            "Batches:   9% 3/32 [00:09<01:31,  3.17s/it]The user disconnected!\n",
            "2024-06-11 15:00:24 - Translation file for ja not found. Using default translation en-US.\n",
            "2024-06-11 15:00:24 - Translated markdown file for ja not found. Defaulting to chainlit.md.\n",
            "Batches:  12% 4/32 [00:12<01:24,  3.01s/it]2024-06-11 15:00:25 - 1 change detected\n",
            "Batches:  16% 5/32 [00:15<01:16,  2.82s/it]2024-06-11 15:00:27 - 1 change detected\n",
            "Batches:  25% 8/32 [00:18<00:38,  1.61s/it]2024-06-11 15:00:31 - Translation file for ja not found. Using default translation en-US.\n",
            "Batches:  47% 15/32 [00:24<00:13,  1.23it/s]2024-06-11 15:00:36 - Translation file for ja not found. Using default translation en-US.\n",
            "Batches: 100% 32/32 [00:29<00:00,  1.09it/s]\n",
            "2024-06-11 15:00:41 - 2 changes detected\n",
            "2024-06-11 15:00:41 - 2 changes detected\n",
            "2024-06-11 15:00:41 - 2 changes detected\n",
            "2024-06-11 15:00:41 - 2 changes detected\n",
            "2024-06-11 15:00:42 - 2 changes detected\n",
            "2024-06-11 15:00:42 - 2 changes detected\n",
            "2024-06-11 15:00:42 - 1 change detected\n",
            "2024-06-11 15:00:42 - 1 change detected\n",
            "2024-06-11 15:00:42 - 1 change detected\n",
            "2024-06-11 15:00:42 - 2 changes detected\n",
            "2024-06-11 15:00:42 - Translation file for ja not found. Using default translation en-US.\n",
            "2024-06-11 15:00:45 - 5 changes detected\n",
            "2024-06-11 15:00:45 - 3 changes detected\n",
            "Batches: 100% 1/1 [00:00<00:00, 62.16it/s]\n",
            "Batches: 100% 1/1 [00:00<00:00, 86.35it/s]\n",
            "Batches: 100% 1/1 [00:00<00:00, 96.45it/s]\n",
            "Batches: 100% 1/1 [00:00<00:00, 88.81it/s]\n",
            "Batches: 100% 1/1 [00:00<00:00, 92.70it/s]\n",
            "Batches: 100% 1/1 [00:00<00:00, 87.69it/s]\n",
            "Batches: 100% 1/1 [00:00<00:00, 93.52it/s]\n",
            "Batches: 100% 1/1 [00:00<00:00, 96.01it/s]\n",
            "Batches: 100% 1/1 [00:00<00:00, 86.63it/s]\n",
            "Batches: 100% 1/1 [00:00<00:00, 86.79it/s]\n",
            "        Graphics:\n",
            "ARK: Survival Evolved has incredible graphics, with a massive and immersive world that is a joy to explore. The game's visuals are breathtaking, with detailed environments and realistic animations that bring the prehistoric setting to life. From the lush forests to the scorching deserts, each environment is visually stunning and offers a unique challenge for players.\n",
            "                        Gameplay:\n",
            "ARK: Survival Evolved offers a wide range of gameplay mechanics that are both fun and challenging. The game allows players to build and craft structures, tame and ride dinosaurs, and battle against other players or AI-controlled foes. The survival aspect of the game is also well implemented, with a deep crafting system and resource management that requires careful planning and strategy. Additionally, the game's combat mechanics are satisfying and enjoyable, with a variety of weapons and abilities to master.\n",
            "                        Replayability:\n",
            "ARK: Survival Evolved has high replayability due to its vast and complex world, as well as its many different biomes and environments. Players can also customize their game experience by choosing from a wide range of dinosaurs to tame and ride, each with unique abilities and characteristics. Additionally, the game's multiplayer feature allows players to team up with friends or join public servers, adding an extra layer of excitement and challenge to the gameplay experience.\n",
            "                        Mechanics:\n",
            "ARK: Survival2024-06-11 15:00:57 - 1 change detected\n",
            " Evolved has a wide range of mechanics that add depth and complexity to the gameplay. From building and crafting to taming and riding dinosaurs, each mechanic is well implemented and requires careful planning and execution. The game's resource2024-06-11 15:00:58 - 1 change detected\n",
            " management system is also well done, with a variety of resources available for players to gather and use. Additionally, the game's combat mechanics are satisfying and enjoyable, with a variety of weapons and abilities to master.\n",
            "                        Difficulty:\n",
            "ARK: Survival Evolved has a challenging difficulty level that requires players to think strategically and plan carefully. The game's AI-controlled foes can be relentless and unforgiving, making it difficult for players to progress without careful planning and strategy. Additionally, the game's survival aspect adds an extra layer of challenge, as players must manage their resources and keep themselves alive in a dangerous and unpredictable world.\n",
            "                        Modding:\n",
            "ARK: Survival Evolved has a thriving modding community that offers a wide range of custom content for players to use. From new dinosaurs and structures to gameplay mechanics and visuals, there are countless options available for players who want to customize their experience. Additionally, the game's development team is actively involved in the modding community, offering support and resources for mod creators.\n",
            "                        Value:\n",
            "ARK: Survival Evolved offers excellent value for2024-06-11 15:01:06 - 1 change detected\n",
            " its price, with hundreds of hours of content available for players to explore. The game's massive world and complex mechanics provide a rich and rewarding experience that is well worth the cost. Additionally, the game's frequent updates and new content additions ensure that players will have plenty of reasons to keep playing long after they've completed the main content.\n",
            "llama_print_timings:        load time =     913.41 ms\n",
            "llama_print_timings:      sample time =     546.50 ms /   726 runs   (    0.75 ms per token,  1328.45 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1323.40 ms /   864 tokens (    1.53 ms per token,   652.87 tokens per second)\n",
            "llama_print_timings:        eval time =   19238.61 ms /   725 runs   (   26.54 ms per token,    37.68 tokens per second)\n",
            "llama_print_timings:       total time =   22428.95 ms /  1589 tokens\n",
            "2024-06-11 15:01:09 - 1 change detected\n",
            "2024-06-11 15:01:15 - 1 change detected\n",
            "2024-06-11 15:01:39 - Translation file for ja not found. Using default translation en-US.\n",
            "2024-06-11 15:01:46 - Translation file for ja not found. Using default translation en-US.\n",
            "The user disconnected!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-06-11T15:01:54+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8000-8803a7eb-18f9-4bf4-85a1-1166614293fe acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2024-06-11T15:01:54+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-8000-8803a7eb-18f9-4bf4-85a1-1166614293fe err=\"failed to start tunnel: session closed\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!chainlit run ui.py -w"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
